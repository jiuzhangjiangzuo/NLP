{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone https://github.com/sonos/nlu-benchmark to the same level as nlu folder\n",
    "DATA_PATH = \"../nlu-benchmark/2017-06-custom-intent-engines\"\n",
    "DEFAULT_SLOT_LABEL = \"unspecified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain:PlayMusic Size:300\n",
      "Domain:PlayMusic Size:300\n",
      "Domain:RateBook Size:300\n",
      "Domain:RateBook Size:300\n",
      "Domain:SearchCreativeWork Size:300\n",
      "Domain:SearchCreativeWork Size:300\n",
      "Domain:GetWeather Size:300\n",
      "Domain:GetWeather Size:300\n",
      "Domain:BookRestaurant Size:300\n",
      "Domain:BookRestaurant Size:300\n",
      "Domain:AddToPlaylist Size:300\n",
      "Domain:AddToPlaylist Size:300\n",
      "Domain:SearchScreeningEvent Size:300\n",
      "Domain:SearchScreeningEvent Size:300\n"
     ]
    }
   ],
   "source": [
    "cls_label_set = set()\n",
    "weather_seq_label_set = set()\n",
    "\n",
    "cls_train_input = []\n",
    "cls_train_label = []\n",
    "weather_seq_train_input = []\n",
    "weather_seq_train_label = []\n",
    "\n",
    "cls_val_input = []\n",
    "cls_val_label = []\n",
    "weather_seq_val_input = []\n",
    "weather_seq_val_label = []\n",
    "\n",
    "\n",
    "def read_data(subdir, domain, dataset):\n",
    "    cls_input, cls_label, seq_input, seq_label = [],[],[],[]\n",
    "    with open(os.path.join(subdir, \"train_{}.json\".format(domain))) as domain_file:\n",
    "        domain_data = json.load(domain_file)\n",
    "        domain_items = domain_data[domain]\n",
    "        for item in domain_items:\n",
    "            sentence_tokens = []\n",
    "            sentence_labels = []\n",
    "            for part in item['data']:\n",
    "                tokens = part['text'].strip().split()\n",
    "                sentence_tokens += tokens\n",
    "                for token in tokens:\n",
    "                    if 'entity' in part:\n",
    "                        sentence_labels.append(part['entity'])\n",
    "                    else:\n",
    "                        sentence_labels.append(DEFAULT_SLOT_LABEL)\n",
    "            cls_input.append(sentence_tokens)\n",
    "            cls_label.append(domain)\n",
    "            \n",
    "            assert len(sentence_tokens) == len(sentence_labels)\n",
    "            seq_input.append(sentence_tokens)\n",
    "            seq_label.append(sentence_labels)\n",
    "    print(\"Domain:{} Size:{}\".format(domain, len(cls_input)))\n",
    "    return cls_input, cls_label, seq_input, seq_label\n",
    "                \n",
    "for domain in os.listdir(DATA_PATH):\n",
    "    subdir = os.path.join(DATA_PATH, domain)\n",
    "    if os.path.isdir(subdir):\n",
    "        cls_label_set.add(domain)\n",
    "        cls_input, cls_label, seq_train_input, seq_train_label = \\\n",
    "        read_data(subdir, domain, 'train')\n",
    "        cls_train_input += cls_input\n",
    "        cls_train_label += cls_label\n",
    "        cls_input, cls_label, seq_val_input, seq_val_label = \\\n",
    "        read_data(subdir, domain, 'validate')\n",
    "        cls_val_input += cls_input\n",
    "        cls_val_label += cls_label\n",
    "        if domain == 'GetWeather':\n",
    "            weather_seq_train_input = seq_train_input\n",
    "            weather_seq_train_label = seq_train_label\n",
    "            weather_seq_val_input = seq_val_input\n",
    "            weather_seq_val_label = seq_val_label\n",
    "            \n",
    "            for seq_label in weather_seq_train_label:\n",
    "                weather_seq_label_set |= set(seq_label)\n",
    "            \n",
    "            for seq_label in weather_seq_val_label:\n",
    "                weather_seq_label_set |= set(seq_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'd like to hear music that's popular from Trick-trick on the Slacker service ---> PlayMusic\n",
      "How's ---> unspecified\n",
      "the ---> unspecified\n",
      "weather ---> unspecified\n",
      "in ---> unspecified\n",
      "Munchique ---> geographic_poi\n",
      "National ---> geographic_poi\n",
      "Natural ---> geographic_poi\n",
      "Park ---> geographic_poi\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(cls_train_input[0]), '--->' , cls_train_label[0])\n",
    "for token, label in zip(weather_seq_train_input[0], weather_seq_train_label[0]):\n",
    "    print(token, '--->', label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BookRestaurant', 'AddToPlaylist', 'PlayMusic', 'RateBook', 'GetWeather', 'SearchCreativeWork', 'SearchScreeningEvent'}\n",
      "{'spatial_relation', 'geographic_poi', 'state', 'current_location', 'condition_description', 'condition_temperature', 'city', 'country', 'timeRange', 'unspecified'}\n"
     ]
    }
   ],
   "source": [
    "print(cls_label_set)\n",
    "print(weather_seq_label_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "def vectorization(train_x, train_y, validate_x, validate_y, label_list, task=\"classification\"):\n",
    "    word2ind = {}\n",
    "    ind2word = {}\n",
    "    specialtokens = ['<pad>','<unk>'] \n",
    "    \n",
    "    def addword(word2ind, ind2word, word):\n",
    "        if word in word2ind:\n",
    "            return\n",
    "        ind2word[len(word2ind)] = word\n",
    "        word2ind[word] = len(word2ind)\n",
    "\n",
    "    for token in specialtokens:\n",
    "        addword(word2ind, ind2word, token)\n",
    "\n",
    "    for sent in train_x:\n",
    "        for word in sent:\n",
    "            addword(word2ind, ind2word, word)\n",
    "\n",
    "    train_x_ids = []\n",
    "    for sent in train_x:\n",
    "        indsent = [word2ind.get(i, word2ind['<unk>']) for i in sent]\n",
    "        train_x_ids.append(indsent)\n",
    "\n",
    "    train_x_ids = np.array(train_x_ids, dtype=object)\n",
    "\n",
    "    validate_x_ids = []\n",
    "    for sent in validate_x:\n",
    "        indsent = [word2ind.get(i, word2ind['<unk>']) for i in sent]\n",
    "        validate_x_ids.append(indsent)\n",
    "\n",
    "    validate_x_ids = np.array(validate_x_ids, dtype=object)\n",
    "    train_x_ids = keras.preprocessing.sequence.pad_sequences(train_x_ids, maxlen=64, padding='post',value=word2ind['<pad>'])\n",
    "    validate_x_ids = keras.preprocessing.sequence.pad_sequences(validate_x_ids, maxlen=64, padding='post',value=word2ind['<pad>'])\n",
    "    \n",
    "    train_y_ids = []\n",
    "    validate_y_ids = []\n",
    "    if task == \"classification\":\n",
    "        for label in train_y:\n",
    "            train_y_ids.append(label_list.index(label))\n",
    "        for label in validate_y:\n",
    "            validate_y_ids.append(label_list.index(label))\n",
    "        train_y_ids = np.array(train_y_ids)\n",
    "        validate_y_ids = np.array(validate_y_ids)\n",
    "    elif task == \"slot_labeling\":\n",
    "        for seq_labels in train_y:\n",
    "            seq_label_ids = []\n",
    "            for label in seq_labels:\n",
    "                seq_label_ids.append(label_list.index(label))\n",
    "            train_y_ids.append(seq_label_ids)\n",
    "        for seq_labels in validate_y:\n",
    "            seq_label_ids = []\n",
    "            for label in seq_labels:\n",
    "                seq_label_ids.append(label_list.index(label))\n",
    "            validate_y_ids.append(seq_label_ids)\n",
    "        train_y_ids = keras.preprocessing.sequence.pad_sequences(train_y_ids, maxlen=64, padding='post',value=label_list.index('unspecified'))            \n",
    "        validate_y_ids = keras.preprocessing.sequence.pad_sequences(validate_y_ids, maxlen=64, padding='post',value=label_list.index('unspecified'))            \n",
    "    \n",
    "    return word2ind, train_x_ids, train_y_ids, validate_x_ids, validate_y_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PlayMusic', 'PlayMusic', 'PlayMusic', 'PlayMusic', 'PlayMusic']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_train_label[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls_label_list = list(cls_label_set)\n",
    "cls_word2ind, cls_train_x_ids, cls_train_y_ids, \\\n",
    "    cls_validate_x_ids, cls_validate_y_ids = \\\n",
    "                vectorization(cls_train_input, cls_train_label, \\\n",
    "                      cls_val_input, cls_val_label, cls_label_list, task=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_seq_label_list = list(weather_seq_label_set)\n",
    "weather_seq_label_list.remove('unspecified')\n",
    "weather_seq_label_list.insert(0, 'unspecified')\n",
    "weather_seq_word2ind, weather_seq_train_x_ids, weather_seq_train_y_ids, \\\n",
    "    weather_seq_validate_x_ids, weather_seq_validate_y_ids = \\\n",
    "                vectorization(weather_seq_train_input, weather_seq_train_label, \\\n",
    "                      weather_seq_val_input, weather_seq_val_label, weather_seq_label_list, task=\"slot_labeling\")\n",
    "\n",
    "weather_seq_sample_weight = np.ones(weather_seq_train_y_ids.shape)\n",
    "for i, seq in enumerate(weather_seq_train_y_ids):\n",
    "    for j, label in enumerate(seq):\n",
    "        if label == weather_seq_label_list.index('unspecified'):\n",
    "            weather_seq_sample_weight[i][j] = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "cls_data = {\n",
    "    'word2ind': cls_word2ind,\n",
    "    'label_list': cls_label_list,\n",
    "    'train_x': cls_train_x_ids,\n",
    "    'train_y': cls_train_y_ids,\n",
    "    'val_x': cls_validate_x_ids,\n",
    "    'val_y': cls_validate_y_ids\n",
    "}\n",
    "\n",
    "weather_seq_data = {\n",
    "    'word2ind': weather_seq_word2ind,\n",
    "    'label_list': weather_seq_label_list,\n",
    "    'train_x': weather_seq_train_x_ids,\n",
    "    'train_y': weather_seq_train_y_ids,\n",
    "    'sample_weight': weather_seq_sample_weight,\n",
    "    'val_x': weather_seq_validate_x_ids,\n",
    "    'val_y': weather_seq_validate_y_ids    \n",
    "}\n",
    "\n",
    "pickle.dump(cls_data, open('cls_data.pickle', 'wb'))\n",
    "pickle.dump(weather_seq_data, open('weather_seq_data.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://api.openweathermap.org/data/2.5/weather?q=London&appid=421126fbad51c268744e7cfece50779f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = json.loads(ret.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'coord': {'lon': -0.1257, 'lat': 51.5085},\n",
       " 'weather': [{'id': 800,\n",
       "   'main': 'Clear',\n",
       "   'description': 'clear sky',\n",
       "   'icon': '01d'}],\n",
       " 'base': 'stations',\n",
       " 'main': {'temp': 283.88,\n",
       "  'feels_like': 283.33,\n",
       "  'temp_min': 281.61,\n",
       "  'temp_max': 285.92,\n",
       "  'pressure': 1017,\n",
       "  'humidity': 89},\n",
       " 'visibility': 8000,\n",
       " 'wind': {'speed': 0.45, 'deg': 102, 'gust': 1.79},\n",
       " 'clouds': {'all': 5},\n",
       " 'dt': 1622523603,\n",
       " 'sys': {'type': 2,\n",
       "  'id': 2019646,\n",
       "  'country': 'GB',\n",
       "  'sunrise': 1622519344,\n",
       "  'sunset': 1622578079},\n",
       " 'timezone': 3600,\n",
       " 'id': 2643743,\n",
       " 'name': 'London',\n",
       " 'cod': 200}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
